{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-20T14:31:59.121475Z","iopub.execute_input":"2022-07-20T14:31:59.121967Z","iopub.status.idle":"2022-07-20T14:31:59.164628Z","shell.execute_reply.started":"2022-07-20T14:31:59.121843Z","shell.execute_reply":"2022-07-20T14:31:59.163731Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pyspark-test-data/test1.csv\n/kaggle/input/pyspark-test-data/test2.csv\n/kaggle/input/pyspark-test-data/tips.csv\n/kaggle/input/pyspark-test-data/test3.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyspark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:31:59.166253Z","iopub.execute_input":"2022-07-20T14:31:59.166817Z","iopub.status.idle":"2022-07-20T14:32:47.606380Z","shell.execute_reply.started":"2022-07-20T14:31:59.166771Z","shell.execute_reply":"2022-07-20T14:32:47.604975Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.3.0.tar.gz (281.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.7/site-packages (from pyspark) (0.10.9.5)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.3.0-py2.py3-none-any.whl size=281764026 sha256=8156746f1d62192a77469818ec558a861a16683f9847aa280d46c32f0f883833\n  Stored in directory: /root/.cache/pip/wheels/7a/8e/1b/f73a52650d2e5f337708d9f6a1750d451a7349a867f928b885\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.3.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import pyspark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:47.609587Z","iopub.execute_input":"2022-07-20T14:32:47.610423Z","iopub.status.idle":"2022-07-20T14:32:47.687090Z","shell.execute_reply.started":"2022-07-20T14:32:47.610366Z","shell.execute_reply":"2022-07-20T14:32:47.685853Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(\"../input/pyspark-test-data/test1.csv\")\ntype(df)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:47.689031Z","iopub.execute_input":"2022-07-20T14:32:47.689606Z","iopub.status.idle":"2022-07-20T14:32:47.710530Z","shell.execute_reply.started":"2022-07-20T14:32:47.689572Z","shell.execute_reply":"2022-07-20T14:32:47.709165Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"pandas.core.frame.DataFrame"},"metadata":{}}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:47.713905Z","iopub.execute_input":"2022-07-20T14:32:47.714385Z","iopub.status.idle":"2022-07-20T14:32:47.737020Z","shell.execute_reply.started":"2022-07-20T14:32:47.714338Z","shell.execute_reply":"2022-07-20T14:32:47.736148Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"        Name  age  Experience  Salary\n0      Krish   31          10   30000\n1  Sudhanshu   30           8   25000\n2      Sunny   29           4   20000\n3       Paul   24           3   20000\n4     Harsha   21           1   15000\n5    Shubham   23           2   18000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Name</th>\n      <th>age</th>\n      <th>Experience</th>\n      <th>Salary</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Krish</td>\n      <td>31</td>\n      <td>10</td>\n      <td>30000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sudhanshu</td>\n      <td>30</td>\n      <td>8</td>\n      <td>25000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sunny</td>\n      <td>29</td>\n      <td>4</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Paul</td>\n      <td>24</td>\n      <td>3</td>\n      <td>20000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Harsha</td>\n      <td>21</td>\n      <td>1</td>\n      <td>15000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Shubham</td>\n      <td>23</td>\n      <td>2</td>\n      <td>18000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('Practise').getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:47.739848Z","iopub.execute_input":"2022-07-20T14:32:47.740955Z","iopub.status.idle":"2022-07-20T14:32:53.413247Z","shell.execute_reply.started":"2022-07-20T14:32:47.740907Z","shell.execute_reply":"2022-07-20T14:32:53.411862Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"22/07/20 14:32:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"spark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:53.418963Z","iopub.execute_input":"2022-07-20T14:32:53.419542Z","iopub.status.idle":"2022-07-20T14:32:54.455729Z","shell.execute_reply.started":"2022-07-20T14:32:53.419500Z","shell.execute_reply":"2022-07-20T14:32:54.454481Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7fa7c7855b10>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://1b16a23d5f37:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Practise</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark = spark.read.csv('../input/pyspark-test-data/test1.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:54.457525Z","iopub.execute_input":"2022-07-20T14:32:54.458022Z","iopub.status.idle":"2022-07-20T14:32:59.744397Z","shell.execute_reply.started":"2022-07-20T14:32:54.457981Z","shell.execute_reply":"2022-07-20T14:32:59.742737Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df_pyspark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:59.745993Z","iopub.execute_input":"2022-07-20T14:32:59.747355Z","iopub.status.idle":"2022-07-20T14:32:59.802340Z","shell.execute_reply.started":"2022-07-20T14:32:59.747303Z","shell.execute_reply":"2022-07-20T14:32:59.800965Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DataFrame[_c0: string, _c1: string, _c2: string, _c3: string]"},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:32:59.804737Z","iopub.execute_input":"2022-07-20T14:32:59.805679Z","iopub.status.idle":"2022-07-20T14:33:00.244491Z","shell.execute_reply.started":"2022-07-20T14:32:59.805606Z","shell.execute_reply":"2022-07-20T14:33:00.243209Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"+---------+---+----------+------+\n|      _c0|_c1|       _c2|   _c3|\n+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n+---------+---+----------+------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df_pyspark=spark.read.option('header','true').csv('../input/pyspark-test-data/test1.csv')","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:00.251547Z","iopub.execute_input":"2022-07-20T14:33:00.252104Z","iopub.status.idle":"2022-07-20T14:33:00.642298Z","shell.execute_reply.started":"2022-07-20T14:33:00.252052Z","shell.execute_reply":"2022-07-20T14:33:00.641001Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_pyspark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:00.643658Z","iopub.execute_input":"2022-07-20T14:33:00.648049Z","iopub.status.idle":"2022-07-20T14:33:00.658525Z","shell.execute_reply.started":"2022-07-20T14:33:00.647980Z","shell.execute_reply":"2022-07-20T14:33:00.657760Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataFrame[Name: string, age: string, Experience: string, Salary: string]"},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:00.660774Z","iopub.execute_input":"2022-07-20T14:33:00.661965Z","iopub.status.idle":"2022-07-20T14:33:00.859487Z","shell.execute_reply.started":"2022-07-20T14:33:00.661914Z","shell.execute_reply":"2022-07-20T14:33:00.858117Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"+---------+---+----------+------+\n|     Name|age|Experience|Salary|\n+---------+---+----------+------+\n|    Krish| 31|        10| 30000|\n|Sudhanshu| 30|         8| 25000|\n|    Sunny| 29|         4| 20000|\n|     Paul| 24|         3| 20000|\n|   Harsha| 21|         1| 15000|\n|  Shubham| 23|         2| 18000|\n+---------+---+----------+------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"type(df_pyspark)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:00.860922Z","iopub.execute_input":"2022-07-20T14:33:00.861394Z","iopub.status.idle":"2022-07-20T14:33:00.874726Z","shell.execute_reply.started":"2022-07-20T14:33:00.861350Z","shell.execute_reply":"2022-07-20T14:33:00.873402Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"pyspark.sql.dataframe.DataFrame"},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:00.876748Z","iopub.execute_input":"2022-07-20T14:33:00.877767Z","iopub.status.idle":"2022-07-20T14:33:01.044911Z","shell.execute_reply.started":"2022-07-20T14:33:00.877719Z","shell.execute_reply":"2022-07-20T14:33:01.043662Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"[Row(Name='Krish', age='31', Experience='10', Salary='30000'),\n Row(Name='Sudhanshu', age='30', Experience='8', Salary='25000'),\n Row(Name='Sunny', age='29', Experience='4', Salary='20000'),\n Row(Name='Paul', age='24', Experience='3', Salary='20000'),\n Row(Name='Harsha', age='21', Experience='1', Salary='15000')]"},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark.printSchema()\n#df.info()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T14:33:01.046871Z","iopub.execute_input":"2022-07-20T14:33:01.047780Z","iopub.status.idle":"2022-07-20T14:33:01.058127Z","shell.execute_reply.started":"2022-07-20T14:33:01.047728Z","shell.execute_reply":"2022-07-20T14:33:01.056822Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"root\n |-- Name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- Experience: string (nullable = true)\n |-- Salary: string (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}