{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-07-20T17:31:17.482893Z","iopub.execute_input":"2022-07-20T17:31:17.483667Z","iopub.status.idle":"2022-07-20T17:31:17.500823Z","shell.execute_reply.started":"2022-07-20T17:31:17.483529Z","shell.execute_reply":"2022-07-20T17:31:17.499613Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/pyspark-test-data/test1.csv\n/kaggle/input/pyspark-test-data/test2.csv\n/kaggle/input/pyspark-test-data/tips.csv\n/kaggle/input/pyspark-test-data/test3.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyspark\nimport pyspark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:17.503807Z","iopub.execute_input":"2022-07-20T17:31:17.504508Z","iopub.status.idle":"2022-07-20T17:31:26.624002Z","shell.execute_reply.started":"2022-07-20T17:31:17.504461Z","shell.execute_reply":"2022-07-20T17:31:26.622768Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pyspark in /opt/conda/lib/python3.7/site-packages (3.3.0)\nRequirement already satisfied: py4j==0.10.9.5 in /opt/conda/lib/python3.7/site-packages (from pyspark) (0.10.9.5)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark=SparkSession.builder.appName('Practise').getOrCreate()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:26.625885Z","iopub.execute_input":"2022-07-20T17:31:26.626248Z","iopub.status.idle":"2022-07-20T17:31:31.137116Z","shell.execute_reply.started":"2022-07-20T17:31:26.626214Z","shell.execute_reply":"2022-07-20T17:31:31.136121Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","output_type":"stream"},{"name":"stdout","text":"22/07/20 17:31:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"}]},{"cell_type":"code","source":"df_pyspark=spark.read.csv('../input/pyspark-test-data/test3.csv',header=True,inferSchema=True)\ndf_pyspark.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:31.138273Z","iopub.execute_input":"2022-07-20T17:31:31.139232Z","iopub.status.idle":"2022-07-20T17:31:37.501285Z","shell.execute_reply.started":"2022-07-20T17:31:31.139193Z","shell.execute_reply":"2022-07-20T17:31:37.499984Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"+---------+------------+------+\n|     Name| Departments|salary|\n+---------+------------+------+\n|    Krish|Data Science| 10000|\n|    Krish|         IOT|  5000|\n|   Mahesh|    Big Data|  4000|\n|    Krish|    Big Data|  4000|\n|   Mahesh|Data Science|  3000|\n|Sudhanshu|Data Science| 20000|\n|Sudhanshu|         IOT| 10000|\n|Sudhanshu|    Big Data|  5000|\n|    Sunny|Data Science| 10000|\n|    Sunny|    Big Data|  2000|\n+---------+------------+------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"spark","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:37.504587Z","iopub.execute_input":"2022-07-20T17:31:37.505065Z","iopub.status.idle":"2022-07-20T17:31:37.523480Z","shell.execute_reply.started":"2022-07-20T17:31:37.505018Z","shell.execute_reply":"2022-07-20T17:31:37.522154Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7f5a5dc08050>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://8a8fc3a531e7:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.3.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Practise</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"code","source":"df_pyspark.printSchema()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:37.525067Z","iopub.execute_input":"2022-07-20T17:31:37.526178Z","iopub.status.idle":"2022-07-20T17:31:37.543135Z","shell.execute_reply.started":"2022-07-20T17:31:37.526130Z","shell.execute_reply":"2022-07-20T17:31:37.541569Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"root\n |-- Name: string (nullable = true)\n |-- Departments: string (nullable = true)\n |-- salary: integer (nullable = true)\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the sum salary by name\ndf_pyspark1 = df_pyspark.groupBy('Name').sum()\ndf_pyspark1.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:37.545187Z","iopub.execute_input":"2022-07-20T17:31:37.546235Z","iopub.status.idle":"2022-07-20T17:31:38.707207Z","shell.execute_reply.started":"2022-07-20T17:31:37.546196Z","shell.execute_reply":"2022-07-20T17:31:38.705949Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"+---------+-----------+\n|     Name|sum(salary)|\n+---------+-----------+\n|Sudhanshu|      35000|\n|    Sunny|      12000|\n|    Krish|      19000|\n|   Mahesh|       7000|\n+---------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the sum salary by Departments\ndf_pyspark1 = df_pyspark.groupBy('Departments').sum()\ndf_pyspark1.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:38.708417Z","iopub.execute_input":"2022-07-20T17:31:38.708860Z","iopub.status.idle":"2022-07-20T17:31:39.211173Z","shell.execute_reply.started":"2022-07-20T17:31:38.708817Z","shell.execute_reply":"2022-07-20T17:31:39.209988Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"+------------+-----------+\n| Departments|sum(salary)|\n+------------+-----------+\n|         IOT|      15000|\n|    Big Data|      15000|\n|Data Science|      43000|\n+------------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the mean salary by Departments\n### Mean is based on how many no of people are working on that departments\n\ndf_pyspark1 = df_pyspark.groupBy('Departments').mean()\ndf_pyspark1.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:39.212389Z","iopub.execute_input":"2022-07-20T17:31:39.212842Z","iopub.status.idle":"2022-07-20T17:31:39.675158Z","shell.execute_reply.started":"2022-07-20T17:31:39.212796Z","shell.execute_reply":"2022-07-20T17:31:39.673881Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"+------------+-----------+\n| Departments|avg(salary)|\n+------------+-----------+\n|         IOT|     7500.0|\n|    Big Data|     3750.0|\n|Data Science|    10750.0|\n+------------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"### Count No of employees in each department\ndf_pyspark1 = df_pyspark.groupBy('Departments').count()\ndf_pyspark1.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:39.676410Z","iopub.execute_input":"2022-07-20T17:31:39.676868Z","iopub.status.idle":"2022-07-20T17:31:40.068227Z","shell.execute_reply.started":"2022-07-20T17:31:39.676824Z","shell.execute_reply":"2022-07-20T17:31:40.066876Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"+------------+-----+\n| Departments|count|\n+------------+-----+\n|         IOT|    2|\n|    Big Data|    4|\n|Data Science|    4|\n+------------+-----+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"### Direct aggreagate function \ndf_pyspark2 = df_pyspark.agg({'Salary':'sum'})\ndf_pyspark2.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:40.075611Z","iopub.execute_input":"2022-07-20T17:31:40.076165Z","iopub.status.idle":"2022-07-20T17:31:40.366770Z","shell.execute_reply.started":"2022-07-20T17:31:40.076112Z","shell.execute_reply":"2022-07-20T17:31:40.365530Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"+-----------+\n|sum(Salary)|\n+-----------+\n|      73000|\n+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the max salary by name in the records\ndf_pyspark3 = df_pyspark.groupBy('Name').max()\ndf_pyspark3.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:40.368009Z","iopub.execute_input":"2022-07-20T17:31:40.368369Z","iopub.status.idle":"2022-07-20T17:31:40.717490Z","shell.execute_reply.started":"2022-07-20T17:31:40.368340Z","shell.execute_reply":"2022-07-20T17:31:40.716355Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"+---------+-----------+\n|     Name|max(salary)|\n+---------+-----------+\n|Sudhanshu|      20000|\n|    Sunny|      10000|\n|    Krish|      10000|\n|   Mahesh|       4000|\n+---------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the min salary by name in the records\ndf_pyspark3 = df_pyspark.groupBy('Name').min()\ndf_pyspark3.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:40.718630Z","iopub.execute_input":"2022-07-20T17:31:40.719043Z","iopub.status.idle":"2022-07-20T17:31:41.099701Z","shell.execute_reply.started":"2022-07-20T17:31:40.719000Z","shell.execute_reply":"2022-07-20T17:31:41.098405Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"+---------+-----------+\n|     Name|min(salary)|\n+---------+-----------+\n|Sudhanshu|       5000|\n|    Sunny|       2000|\n|    Krish|       4000|\n|   Mahesh|       3000|\n+---------+-----------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"## Groupby\n### Grouped to find the mean salary by name \ndf_pyspark3 = df_pyspark.groupBy('Name').avg()\ndf_pyspark3.show()","metadata":{"execution":{"iopub.status.busy":"2022-07-20T17:31:41.101021Z","iopub.execute_input":"2022-07-20T17:31:41.106145Z","iopub.status.idle":"2022-07-20T17:31:41.453327Z","shell.execute_reply.started":"2022-07-20T17:31:41.106079Z","shell.execute_reply":"2022-07-20T17:31:41.452164Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"+---------+------------------+\n|     Name|       avg(salary)|\n+---------+------------------+\n|Sudhanshu|11666.666666666666|\n|    Sunny|            6000.0|\n|    Krish| 6333.333333333333|\n|   Mahesh|            3500.0|\n+---------+------------------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}